\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=blue,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}
\usepackage{multirow}

%\input{../Comments}
%\input{../Common}

\begin{document}

\title{Capstone 4G06: System Verification and Validation Plan for \progname{yoGERT GIS Toolbox}} 
\author{Team 19,
		\\ Smita Singh, Abeer Alyasiri, Niyatha Rangarajan,\\ Moksha Srinivasan, Nicholas Lobo, Longwei Ye \\\\
		\textbf{New VnV Template}
}

\date{November 2, 2022}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
November 2, 2022 & 1.0 & Longwei: Sec 3; Moksha: Sec 6,7; Smita: Sec 6,7; Abeer: Sec 3,4,formatting; Niyatha: 5.2; Nicholas: Sec 5.2,5.3 \\
% Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

\newpage

\tableofcontents

\listoftables
% \wss{Remove this section if it isn't needed}

% \listoffigures
% \wss{Remove this section if it isn't needed}

\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l p{10cm}} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  SRS & Software Requirements Specification \\
  GPS & Global Positioning Systems\\
  GIS & Geographical Information Systems\\
  GERT & GIS-based episode reconstruction toolkit \\
  Point & location coordinate with time stamp.\\
  Session & Object activity history quantified by GPS points \\
  Episode & Session\\
  Segment & Group of GPS Points combined based on episode attributes.\\
  Trip & GPS points represents an object moving to a different position.\\
  Route & Object path to get from position A to position B\\
  Mode Detection (MD) & Detection of type of transportation being used \\
  Time Use Diary (TUD) & Time Use Diary are records of continuous events and actions through a particular period of time (usually 24 to 48 hours) \\
  Route Choice Analysis (RCA) &  Analyzes route selection from point a to point b\\
  .shp & .shp are geospatial data format files\\
  CSV/.csv & Comma Separated Values is a file type that contains large amounts of data separated by commas. \\
  Potential Activity Locations (PALS) & PALS are potential trip stops \\
  Activity Locations (ALs) & ALs are trip stops \\
  FR & Functional Requirement \\
  NFR & Non-Functional Requirement \\


  \bottomrule
\end{tabular}\\

% \wss{symbols, abbreviations or acronyms --- you can simply reference the SRS
%   \citep{SRS} tables, if appropriate}

% \wss{Remove this section if it isn't needed}

\newpage

\pagenumbering{arabic}

This document provides the project's verification and 
validation plan for documentation phase and implementation phase. Also, it will include detailed testing decisions for system test cases and unit test cases.  
% \wss{provide an introductory blurb and roadmap of the
%   Verification and Validation plan}

\section{General Information}

\subsection{Summary}
The software being verified and validated is the \emph{yoGERT} toolbox. The software general functions include:
\begin{itemize}
    \item Process user's GPS files into compatible data types.
    \item Determine choice model estimations.
    \item Extract travel episodes variables.
    \item Extract segments from travel episodes and classify segments.
    \item Categorize movement and stop behaviour. 
\end{itemize}

% \wss{Say what software is being tested.  Give its name and a brief overview of
%   its general functions.}

\subsection{Objectives}
The objectives of the verification and validation plan ordered by importance are:
\begin{enumerate}
    \item To demonstrate the fundamental functions meet the stakeholders goals.
    \item To build confidence in toolbox accessibility and transferability. 
    \item To build confidence in the toolbox correctness. By confirming the functions are executed as expected by the requirements. 
    \item To demonstrate the project scope meets the capstone deadline. 


Demonstrating that the fundamental functions meet the stakeholders' goals is the most important objective because it helps to ensure that the project being developed aligns with the expectations of the stakeholders. This will help improve the overall quality of the products as it will be designed with the end-users in mind. To demonstrate the project scope meets the capstone deadline is the least important objective as it will be completed as long as the other objectives above it are met. 

\end{enumerate}

% \wss{State what is intended to be accomplished.  The objective will be around
%   the qualities that are most important for your project.  You might have
%   something like: ``build confidence in the software correctness,''
%   ``demonstrate adequate usability.'' etc.  You won't list all of the qualities,
%   just those that are most important.}

\subsection{Relevant Documentation}
The test plan are created follow the documents listed below:
\begin{itemize}
    \item Software Requirements Specification.
    \item Module Guide.
    \item Module Interface Specification.
\end{itemize}


% \wss{Reference relevant documentation.  This will definitely include your SRS
%   and your other project documents (design documents, like MG, MIS, etc).  You
%   can include these even before they are written, since by the time the project
%   is done, they will be written.}

% \citet{SRS}

\section{Plan}

% \wss{Introduce this section.   You can provide a roadmap of the sections to
%   come.}
  
This section outlines verification and validation plan including details on possible testing approaches and division of resources. The section provides rationalized decisions making process for the verification and validation plan.

\subsection{Verification and Validation Team}

% \wss{Your teammates.  Maybe your supervisor.
%   You shoud do more than list names.  You should say what each person's role is
%   for the project's verification.  A table is a good way to summarize this information.}
The testing team consists of all members of \emph{yoGERT} team. All team members
need to be actively aware of each testing plan and involved in all aspects of the
testing process. All team members are involved because this is a capstone project
that requires students to participate in all the project's stages. Therefore, the
team aims to evenly split testing and preparing for automated testing. The table
below shows the division of responsibilities. It assigns leaders for different
testing milestones. This way the team is sure that every testing stage is on
track.  
\newpage
\begin{table}[h!]
    \begin{tabular}{|c|p{50mm}|p{50mm}| }
 \hline
 \textbf{Team Member} & \textbf{Testing Role} & \textbf{Responsibilities}  \\ 
 \hline
 Abeer Alyasiri & SRS and Design Verification and Acceptance Testing & Leads document and code walkthroughs and inspections. Leads user and business acceptance testing using black box techniques. \\ 
 Longwei Ye & Integration Testing & Leads regression testing using black box techniques. \\ 
 Moksha Srinivasan & Unit Testing & Leads implementation of white box testing techniques. \\
 Smita Singh & Unit Testing & Leads implementation of white box testing techniques. \\
 Nicholas Lobo & System Testing & Leads functional requirements testing. \\
 Niyatha Rangarajan & System Testing & Leads non-functional requirements testing. \\
 \hline
\end{tabular}
    \caption{Verification and Validation Team.}
    \label{tab:my_label}
\end{table}

\subsection{SRS Verification Plan}

% \wss{List any approaches you intend to use for SRS verification.  This may include
%   ad hoc feedback from reviewers, like your classmates, or you may plan for 
%   something more rigorous/systematic.}
The SRS verification plan consists of three parts. The main objectives is to check
if the SRS document was completed according to the Volere Template Standards and 
if the requirements address the project goals. All parts will utilize a static 
testing technique that includes structured and unstructured reviews, walkthroughs or checklists.\\
Part one is the unstructured feedback received from 
classmates in the form of GitHub issues. These reviews provide technical
improvements on the document from outside the team. It is helpful because it 
improves the document's information flow to professional individuals in the
field, such as software engineers.\\ 
Part two is the structured review received from the TA. The TA follows a checklist in the form of a rubric. The feedback is beneficial because the SRS is reviewed
from an industry standard perspective. Hence, the document will be
closer to implementing best-practices techniques throughout the
document. This increases the productivity of using the SRS during the
design stage.\\ 
Part three is a structured review with the supervisor. The review will be a
combination of SRS walkthrough and modified task based inspection. 
The objectives of the walkthrough is to introduce the supervisor to the 
team's documentation and receive general feedback on the scope and 
clarity of the documentation. On the other hand the task based 
inspection will analyze both functional and non-functional
requirements in depth. The inspection will consist of questions to 
motivate the supervisor to think about the relationship between 
system goals and the formulated requirements. This is helpful with 
removing ambiguities of the requirement's relevance to the desired final system. 
Also, the inspection will focus on problem categorization.
These will represent the talking points of the task based inspection with the supervisor.
The categorizations are clarity of requirements, conflicting requirements, and unrealistic requirements problems. \\
All reviews collected from the SRS verification plan will be applied
to the document before the design document deliverable.

% \wss{Maybe create an SRS checklist?}

\subsection{Design Verification Plan}

Design verification will be similar to the SRS verification part one and
part two. In addition it will include a formal review by teammates using
a checklist. The checklist will consist of Dr. Spencer's MG and MIS checklists and the following points:
\begin{itemize}
    \item Each design decision maps to one or more requirements. 
    \item Each design specification has one output. 
    \item Each function decomposition follow top to down design model.
    \item Design specification connect functional processes logically for the user to carry out tasks.
    \item Design specification does not include implementation details.
    \item Design specification describe inputs, logical operations, and output. 
    \item Design specification outputs are consistent across a division of input cases.
    \item Design specification outlines error responses for unexpected behaviour. 
\end{itemize}

The team will conduct the verification against the checklist using 
static and dynamic testing techniques. Static testing will involve 
a walkthrough to proof traceability and accuracy of the system 
architectural model. Dynamic testing will include unit testing, white box testing, black box testing, and integration testing.

% \wss{Plans for design verification}

% \wss{The review will include reviews by your classmates}

% \wss{Create a checklists?}

\subsection{Verification and Validation Plan Verification Plan}

Verification and validation plan will be verified through reviews. It is important to highlight that it is difficult to proof the correctness of the test cases. Therefore, the combination multiple verification techniques induct that the verification and validation plan  approximately tested critical points of the system.\\ 
First, it will be verified against Dr. Spencer's VnV-checklist by \emph{yoGERT} team members. It will verify the completeness of the test cases. It is done by tracing at least one requirement to a test case and examining the requirement across different types of inputs.\\ 
Second, it will be reviewed by classmates in an informal way. This feedback is beneficial because it is outside the team professional opinion on what information is missing from the document.\\ 
Third, it will be reviewed by the TA in a standard way using the rubric as a checklist. The review will focus on the accuracy of information used to formulate the plan and if the plan is appropriate to the project. The plan is appropriate if it is feasible within the capstone timeline and test cases are complete within its requirement scope. 

% \wss{The verification and validation plan is an artifact that should also be verified.}

% \wss{The review will include reviews by your classmates}

% \wss{Create a checklists?}

\subsection{Implementation Verification Plan}

% \wss{You should at least point to the tests listed in this document and the unit
%   testing plan.}
The implementation verification plan includes both
system test cases and unit test cases listed in this 
document. The verification plan is a combination of 
different testing techniques to start with testing the 
building blocks of the system up to testing structural 
interaction between theses components.\\ 
In the early stages of the implementation verification 
plan, the team will conduct static verification
techniques. It includes code inspections to test code 
readability and code walkthroughs to verify 
implementation meets that design specification. \\
The other stages of the implementation verification plan will rely on dynamic 
testing techniques. These tests will be driven by white box testing and 
integration testing techniques. Both these techniques are focused on proving that 
the system follows the design specification and is consistent with the addition of
new components. Also, The verification plan must encapsulate testing scenarios of how the system reacts to faulty inputs. It can be tested by inputting irrational data points and observing if a safe output will be produced instead of system failure. Therefore, it is important that the testing cases will include boundary and edge inputs to the system's safe outputs and consistent behaviour.


% \wss{In this section you would also give any details of any plans for static verification of
%   the implementation.  Potential techniques include code walkthroughs, code
%   inspection, static analyzers, etc.}

\subsection{Automated Testing and Verification Tools}

% \wss{What tools are you using for automated testing.  Likely a unit testing
%   framework and maybe a profiling tool, like ValGrind.  Other possible tools
%   include a static analyzer, make, continuous integration tools, test coverage
%   tools, etc.  Explain your plans for summarizing code coverage metrics.
%   Linters are another important class of tools.  For the programming language
%   you select, you should look at the available linters.  There may also be tools
%   that verify that coding standards have been respected, like flake9 for
%   Python.}

% \wss{If you have already done this in the development plan, you can point to
% that document.}

% \wss{The details of this section will likely evolve as you get closer to the
%   implementation.}

The section was done in the development plan document Sections 6 and 7. \\

The details of this section will likely evolve further
in the project. Currently the plan is to only use 
automation testing for unit tests. 

\subsection{Software Validation Plan}

% \wss{If there is any external data that can be used for validation, you should
%   point to it here.  If there are no plans for validation, you should state that
%   here.}
  
Software validation plan will be divided into two parts. Part one will involve walkthrough and task based inspection with the supervisor similar to the SRS 
verification plan section. It will be conducted, for the same reasons from before, to flush out any problems with the SRS requirements. This standardized review will be conducted prior to implementation. Part two will involve walkthrough and demonstration to the supervisor to validate that the system behaves as the primary stakeholder expected. The formal walkthrough ensures validation of the design implementation functionality. On the other hand the demonstration validate the system's usability and response to user inputs. The supervisor will be able to provide feedback as he understand the GIS toolbox functionality and he represents a typical user for the \emph{yoGERT} toolbox. 
If time permits, external data can be used for validation. The external data will be ARC GIS outputs to the same inputs fed into the \emph{yoGERT} toolbox. The objective of this validation is to show the consistency between the \emph{yoGERT} toolbox and the current available toolbox. This form of validation need to use external data with exact method applied to since the \emph{yoGERT} toolbox is implementing parts of the ARC GIS application. Hence, not all outputs of the ARC GIS application are the expected outputs from the \emph{yoGERT} toolbox.

% \wss{You might want to use review sessions with the stakeholder to check that
% the requirements document captures the right requirements.  Maybe task based
% inspection?}

% \wss{This section might reference back to the SRS verification section.}

\section{System Test Description}
	
\subsection{Tests for Functional Requirements}

The testing of functional requirements will be divided into two sections. One to test user functionality and one to test system functionality. 

\subsubsection{User Functionality Tests}

This type of software testing that focuses on verifying the functionality of a system or application from the end-user's perspective. The purpose of this testing is to ensure that the software meets the needs and expectations of its intended users by testing all user-facing features. How data is being read will be the main focus of these tests to ensure a high level of user satisfaction with the final product.



		
\paragraph{User Input Testing}

\begin{enumerate}

\item{test-UT-1\\}

\textbf{Control}: Manual 
					
\textbf{Initial State}: The application has been loaded onto the computer
					
\textbf{Input}: User loads in a CSV file of GPS data
				
\textbf{Output}: The system saves the CSV file of GPS data

\textbf{Test Case Derivation}: The user wants the application to read the given CSV file 
					
\textbf{How test will be performed}: Different sets of valid CSV data will be uploaded by the tester to see if the computer reads the values correctly

\textbf{Associated Functional Requirement}: FR1 

\item{test-UT-2\\}

\textbf{Control}: Manual 
					
\textbf{Initial State}: The application has been loaded onto the computer
					
\textbf{Input}: The system has a loaded file of GPS data 
					
\textbf{Output}: The system saves the values found in the CSV file as latitude longitude and time variables

\textbf{Test Case Derivation}: The user wants to use the software to save the given CSV files into variables that can be manipulated
					
\textbf{How test will be performed}: Different sets of valid CSV's of GPS data will be uploaded by the tester to see if the computer reads the values correctly

\textbf{Associated Functional Requirement}: FR2,FR5

\item{test-UT-3\\}

\textbf{Control}: Manual 
					
\textbf{Initial State}: The application has been loaded onto the computer
					
\textbf{Input}: User loads in a CSV file of time use diaries (TUD)
					
\textbf{Output}: The system saves the the the CSV file of TUD's

\textbf{Test Case Derivation}: The user wants to use the software to read the given CSV file and save it
					
\textbf{How test will be performed}: Different sets of valid CSV's of TUD data will be uploaded by the tester to see if the computer reads the values correctly

\textbf{Associated Functional Requirement}: FR3

\item{test-UT-4\\}

\textbf{Control}: Manual 
					
\textbf{Initial State}: A CSV of GPS data has been inputted to the application
					
\textbf{Input}: User downloads the file that it uploaded to the system 
					
\textbf{Output}: The system gives the user the data in a CSV format 

\textbf{Test Case Derivation}: The user wants to use the software to read the given CSV file and save it to attributes that can be 
					
\textbf{How test will be performed}: Different sets of valid CSV's of TUD data will be uploaded by the tester to see if the computer reads the values correctly

\textbf{Associated Functional Requirement}: FR4
\end{enumerate}

\subsubsection{System Functionality Tests}

These tests will have a focus on verifying the internal workings of the system. It will involve testing the individual components and subsystems that make up the system to ensure that they function as intended and interact with each other properly. How data is being processed and outputted will be the main focus of these tests with the goal of identifying and fixing any defects or issues that could affect the overall performance and stability of the system.

\paragraph{System Output Testing}

\begin{enumerate}

\item{test-ST-1\\}

\textbf{Control}: Manual       
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the inputted data into episodes 
					
\textbf{Output}: The system returns a report of categorized data points such as speed, duration, distance, and change in direction.

\textbf{Test Case Derivation}: The system needs to be displayed in a way that the user can read easily

\textbf{How test will be performed}: The tester will use a variety of CSV files filled with valid GPS data and use the function call to see if valid reports were generated


\textbf{Associated Functional Requirement}: FR6



\item{test-ST-2\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: A CSV of TUD data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the inputted data into episodes 
					
\textbf{Output}: The system returns a report which contains a list of episodes that have categorized data points such as speed, duration, distance, and change in direction.

\textbf{Test Case Derivation}: The system needs valid GPS points

\textbf{How test will be performed}: The tester will use a variety of CSV files filled with valid GPS data and use the function call to see if valid reports were generated


\textbf{Associated Functional Requirement}: FR7

\item{test-ST-3\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the inputted data into episodes 
					
\textbf{Output}: The system returns a report of episodes categorized by different  methods of transportation(walk, car, bus).

\textbf{Test Case Derivation}: The user wants to understand the methods of travel used from the set of data points given

\textbf{How test will be performed}: The tester will use a variety of CSV files filled with valid GPS data and use the function call to see if valid categories are found in the reports generated


\textbf{Associated Functional Requirement}: FR8,FR20


\item{test-ST-4\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application and a report of episodes was generated 
					
\textbf{Input}: The user selects one of the episodes generated from the report
					
\textbf{Output}: The system returns the segments of the episodes into type stop and trip 

\textbf{Test Case Derivation}: The user wants to understand the behaviour of the object given an episode in the report

\textbf{How test will be performed}: The tester will use a variety of generated reports to see if valid episode segments were created 


\textbf{Associated Functional Requirement}: FR9,FR19


\item{test-ST-5\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application 
					
\textbf{Input}: The report of episodes and segments are generated
					
\textbf{Output}: The system generates the trip trajectory values based on the given segments

\textbf{Test Case Derivation}: The system needs trip trajectory values for route choice analysis

\textbf{How test will be performed}: The tester will validate the trajectory values based on the given CSV GPS data 

\textbf{Associated Functional Requirement}: FR10

\item{test-ST-6\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application and the report is generated
					
\textbf{Input}: The report of episodes and segments are generated
					
\textbf{Output}: The system generates and stores activity locations for each of the episodes in the report

\textbf{Test Case Derivation}: The system needs to generate high and low activity locations

\textbf{How test will be performed}: The tester will validate a sample reports activity location matches with a curated list of episodes with known activity locations

\textbf{Associated Functional Requirement}: FR11,FR16,18

\item{test-ST-7\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application and the report of episodes and their segments are generated
					
\textbf{Input}: The trajectory values are calculated by the system
					
\textbf{Output}: The system creates RCA variables based on the trip trajectory 

\textbf{Test Case Derivation}: The system needs the RCA variables to define route choice behaviour data set. 

\textbf{How test will be performed}: The tester will generate multiple RCA datasets from different reports and check the validity of them

\textbf{Associated Functional Requirement}: FR12,FR13

\item{test-ST-8\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: A RCA dataset has been generated by the software
					
\textbf{Input}: The user request a route from two GPS points A and B 
					
\textbf{Output}: The system generates a mapped route from position A and position B 

\textbf{Test Case Derivation}: The user needs requested routes given two GPS points

\textbf{How test will be performed}: The tester will request for multiple routes to be created from a generated RCA dataset

\textbf{Associated Functional Requirement}: FR14,FR17

\item{test-ST-9\\}

\textbf{Control}: Manual
					
\textbf{Initial State}: A RCA dataset has been generated by the software
					
\textbf{Input}: The user request a route from two GPS points A and B with selected constraints 
					
\textbf{Output}: The system generates a mapped route from position A and position B with selected constraints

\textbf{Test Case Derivation}: The user wants customized routes based on selected constraints 

\textbf{How test will be performed}: The tester will request for multiple routes with selected constraints be created from a generated RCA dataset

\textbf{Associated Functional Requirement}: R15

\end{enumerate}



\subsection{Tests for Nonfunctional Requirements}

% \paragraph{* Storing user information is now considered as a stretch goal. This conclusion was reached after a dicussion with our stakeholders. Hence, the SRS will be revised to avoid including such information. The following tests do not involve storing user information while the rest of SRS NFR related information remains unchanged. }
\subsubsection{UI/UX Component Readability }
\paragraph{The information must be presented to the user in readable format. Hence, there will be UI/UX related tests.}

\begin{enumerate}

\item{test-id1\\}

\textbf{Type}: Regression testing
					
\textbf{Initial State}: Word document is present in the directory. Various functions to perform on the GPS data are shown to the user.
					
\textbf{Input/Condition}: The user types a function to call for the system to organize the
inputted data (word document) into episodes giving a word document as input. 
					
\textbf{Output/Result}: An error stating that the input file provided is not of the correct format.
					
\textbf{How test will be performed}: Since, different functions require different inputs, it is important to see if the current modules functionality changes when the format of the input file changes.

\textbf{Associated NFR}: 11
\item{test-id2\\}

\textbf{Type}: Manual testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the
inputted data into episodes
					
\textbf{Output}: The system returns a possible set of input data types if the function matches a stored function in the system
					
\textbf{How test will be performed}: This works like VS code, were as you type a function, a function description hovers over the function call, depciting the required user input for that function. One can try this test with different function calls to check its validity.

\textbf{Associated NFR}: 1, 2, 3, 4, 5, 6, 7 
\end{enumerate}

\subsubsection{Large Data Memory and Performance}
\paragraph{The toolbox must work with large sets of data, hence test must consider the edge cases of data size and its relevant processing time. }

\begin{enumerate}

\item{test-id3\\}

\textbf{Type}: Regression testing
					
Initial State: CSV of 47.3 million data points of GPS data has been inputted to the application
					
\textbf{Input/Condition}: The user types a function to call for the system to organize the
inputted data (word document) into episodes giving a word document as input. 
					
\textbf{Output/Result}: The system returns a report of categorized data points such
as speed, duration, distance, and change in direction within 6000 seconds upon request
					
\textbf{How test will be performed}: We perform edge case tests to see if performance and capacity requirements are met. 

\textbf{Associated NFR}: 9, 11, 12

\item{test-id4\\}

\textbf{Type}: Unit testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the
inputted data into episodes
					
\textbf{Output}: The system returns a possible set of input data types if the function matches a stored function in the system
					
\textbf{How test will be performed}: We perform a unit test to see if the outputted data matches the expected episodes we require from the system. This is helpful for precision requirements.

\textbf{Associated NFR}: 11

\end{enumerate}


\subsubsection{User information Security and Reliability}
		
\paragraph{Since the information inputted will be used by APIs online, the system must ensure protection of user information.}

\begin{enumerate}

\item{test-id5\\}

\textbf{Type}: Manual
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input/Condition}: The user types a function to call for the system to organize the
inputted data into episodes
					
\textbf{Output/Result}: No data seen at API endpoint.
					
\textbf{How test will be performed}: We must make sure we use online APIs like pandas, geopy, etc. does not store any user inputted information.

\textbf{Associated NFR}: 19

\item{test-id6\\}

\textbf{Type}: Dynamic testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input}: The user types a function to call for the system to organize the
inputted data into episodes
					
\textbf{Output}: Inputted data has not changed once the episodes are created.
					
\textbf{How test will be performed}: Black box testing using Finite state machines. If there is no change of state for the input, then the test succeeds. 

\textbf{Associated NFR}: 10

\end{enumerate}

\subsubsection{Environment issues}
		
\paragraph{For the functioning of the application, it must have certain prerequisite software like Python installed and the environment it is run on like Mac, Windows, etc. must be accounted for.}

\begin{enumerate}

\item{test-id7\\}

\textbf{Type}: Unit testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input/Condition}: The user types a function to call for the system to organize the
inputted data into episodes. 
					
\textbf{Output/Result}: Error is outputted stating that Python must be installed in the system.
					
\textbf{How test will be performed}: Python is not installed in the system before inputting the data. 

\textbf{Associated NFR}: 15

\item{test-id8\\}

\textbf{Type}: Unit testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input/Condition}: The user types a function to call for the system to organize the
inputted data into episodes. 
					
\textbf{Output/Result}: The system returns a report of categorized data points such
as speed, duration, distance, and change in direction
					
\textbf{How test will be performed}: Python2 is installed in the system before inputting the data. Since, Python can only be installed on a valid OS, we simultaneously test for the operational environment.

\textbf{Associated NFR}: 14,15,16

\subsubsection{Accessibility issues}

\item{test-id9\\}

\textbf{Type}: Manual testing
					
\textbf{Initial State}: CSV of GPS data has been inputted to the application
					
\textbf{Input/Condition}: The user typed a function to call for the system to output the
inputted data into episodes with input to specify file output. 
					
\textbf{Output/Result}: The system returns a report of categorized data points such
as speed, duration, distance, and change in direction in a csv file format to allow output to be saved
					
\textbf{How test will be performed}: The GPS data points are inputs and a function is ran on them with the option to open the output in csv file format.

\textbf{Associated NFR}: 8.

\subsubsection{Scalability issues}

\item{test-id10\\}

\textbf{Type}: Manual testing
					
\textbf{Initial State}: application has a pre-existing data points as inputs
					
\textbf{Input/Condition}: The second user inputs a different set of GPS data points.
					
\textbf{Output/Result}: The system returns a successful message of the accepted inputs and maps them as a continuation of the initial data points. 
					
\textbf{How test will be performed}: The toolbox initialized with an input then an new input is loaded on the toolbox. 

\textbf{Associated NFR}: 13.

\subsubsection{Security issues}
NFRs 17,18  are not applicable to the \emph{yoGERT} toolbox as it was mentioned in the Hazard Analysis document. After the Hazard Analysis NFR changes are applied to the SRS document then appropriate test cases will be described here.

\end{enumerate}
\subsection{Traceability Between Test Cases and Requirements}

\begin{table}[H]
\centering
\scalebox{0.5}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline        
& FR1 & FR2 & FR3 & FR4 & FR5 & FR6 & FR7& FR8 & FR9 & FR10 & FR11 & FR12 & FR13 & FR14 & FR15 & FR16 & FR17 & FR18 & FR19 & FR20\\ \hline
test-UT-1  &X & & & &X & & & & & & & & & & & & & & & \\ \hline
test-UT-2  & &X & & & & & & & & & & & & & & & & & &  \\ \hline
test-UT-3  & & &X & & & & & & & & & & & & & & & & &  \\ \hline
test-UT-4  & & & &X & & & & & & & & & & & & & & & & \\ \hline
test-ST-1  & & & & & &X & & & & & & & & & & & & & &  \\ \hline
test-ST-2  & & & & & & &X & & & & & & & & & & & & & \\ \hline
test-ST-3  & & & & & & & &X & & & & & & & & & & & &X\\ \hline
test-ST-4  & & & & & & & & &X & & & & & & & & & &X & \\ \hline
test-ST-5  & & & & & & & & & &X & & & & & & & & & & \\ \hline
test-ST-6  & & & & & & & & & & &X & & & & &X & &X & & \\ \hline
test-ST-7  & & & & & & & & & & & &X &X & & & & & & & \\ \hline
test-ST-8  & & & & & & & & & & & & & &X & & &X & & & \\ \hline
test-ST-9  & & & & & & & & & & & & & & & X& & & & & \\ \hline



\hline %
\end{tabular}
}
\caption{Traceability Matrix Showing the Connections Between Functional Requirements and their test.}
\label{Table:trace}
\end{table}



\begin{table}[H]
\centering
\scalebox{0.5}{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline        
& NFR1 & NFR2 & NFR3 & NFR4 & NFR5 & NFR6 & NFR7& NFR8 & NFR9 & NFR10 & NFR11 & NFR12 & NFR13 & NFR14 & NFR15 & NFR16 & NFR17 & NFR18 & NFR19\\ \hline
test-id1  & & & & & & & & & & &X & & & &  & & & & \\ \hline
test-id2  &X &X &X &X &X &X &X & & & & & & & &  & & & & \\ \hline
test-id3  & & & & & & & & &X & &X &X & & &  & & & & \\ \hline
test-id4  & & & & & & & & & & &X & & & &  & & & & \\ \hline
test-id5  & & & & & & & & & & & & & & &  & & & &X \\ \hline
test-id6  & & & & & & & & & &X & & & & &  & & & & \\ \hline
test-id7  & & & & & & & & & & & & & & &X  & & & & \\ \hline
test-id8  & & & & & & & & & & & & & &X &X  &X & & & \\ \hline
test-id9  & & & & & & & &X & & & & & & &  & & & & \\ \hline
test-id10  & & & & & & & & & & & & &X & &  & & & & \\ \hline

\hline %
\end{tabular}
}
\caption{Traceability Matrix Showing the Connections Between Non Functional Requirements and their test.}
\label{Table:trace}
\end{table}


\section{Unit Test Description}

The pytest library will be used to complete unit testing for this toolbox. To develop unit tests for the internal functions of the program, we will be creating a corresponding test file for each module. Each test file will contain unit tests for each function within the module. These tests contain a variety of inputs, including those which output the correct transformation as well as inputs that generate errors and exceptions. \\

\noindent We will be using coverage metrics to determine how well-tested our code is. This will be determined through the use of coverage.py, a python library that quickly analyzes code coverage of all modules within a project. We will be aiming for 90\% code coverage per module, ensuring that we adequately test all functions. 
%\wss{Reference your MIS (detailed design document) and explain your overall
 % philosophy for test case selection.}  
%\wss{This section should not be filled in until after the MIS (detailed design
  %document) has been completed.}

\subsection{Unit Testing Scope}

Route choice analysis variable modules will be verified for correct functionality (correct sample inputs output correct sample outputs), but logic of previously existing modules will be assessed for correctness by our supervisor, Dr. Paez.
%\wss{What modules are outside of the scope.  If there are modules that are
%  developed by someone else, then you would say here if you aren't planning on
%  verifying them.  There may also be modules that are part of your software, but
%  have a lower priority for verification than others.  If this is the case,
% 5 explain your rationale for the ranking of module importance.}

\subsection{Tests for Functional Requirements}

This section will be completed once the MIS has been updated and there is greater clarity on specific modules. 

\subsection{Tests for Non-Functional Requirements}

This section will be completed once the MIS has been updated and there is greater clarity on specific modules. 

\subsection{Traceability Between Test Cases and Modules}
This section will be completed once the MIS has been updated and there is greater clarity on specific modules. 
%\wss{Provide evidence that all of the modules have been considered.}
				
\bibliographystyle{plainnat}

\bibliography{../../refs/References}

\newpage

\section{Appendix}

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\begin{enumerate}

\item How easy was it to complete tasks using the system?
\begin{enumerate}
\item Easy
\item Neither easy nor difficult
\item Difficult
\end{enumerate}

\item How satisfied are you with the overall user experience?
\begin{enumerate}
\item Satisfied
\item Neither satisfied nor dissatisfied
\item Dissatisfied
\end{enumerate}

\item Were the instructions clear and easy to understand?
\begin{enumerate}
\item Clear
\item Somewhat clear
\item Not at all clear
\end{enumerate}

\item How often did you encounter errors or issues while using the system?
\begin{enumerate}
\item Never
\item Sometimes
\item Almost always
\end{enumerate}
\end{enumerate}
\newpage{}
\section*{Appendix --- Reflection}
General Team:\\

\noindent To implement the verification and validation plan within our project our team will have to learn a few new skills. The team will have to create a standard testing suite and develop a standard testing method that each member of the team will follow. This will be to ensure that all tests are understandable and readable by all members of the group. \\

\noindent The team will also familiarize themselves with the pytest framework which will allow us to create consistent, efficient tests that will test each function in our program. As well as learn system testing techniques such as ---.  The team will also need to create a testing strategy that is appropriate and feasible for the project.\\

\noindent Smita Singh:\\ Smita will be responsible for creating unit test for Route Choice Analysis. She will need understand the inputs and outputs of each of the methods that will be required to perform that specific module. Smita will also be leading the creation of a test strategy. \\

\noindent Moksha Srinivasan:\\ Similar to Smita, Moksha will also be responsible for creating tests for Route Choice Analysis. Moksha will also be responsible for helping set up the standard test suite and implementing CI/CD into our git repository by following the tutorial given by Chris Shankula. \\

\noindent Longwei Ye:\\
Longwei will be responsible for creating unit testing for trip trajectory. Longwei will be responsible for learning about best testing practises through research and will ensure that the team sticks to those practises.\\

\noindent Niyatha Rangarajan:\\
Niyatha will be creating unit testing module for travel episode verification and categorization. Niyatha has been passionate about end to end system testing. She will be researching how to perform relevant system testing by researching industry standards and then be responsible for informing the rest of the team.\\

\noindent Abeer Alyasiri:\\ Abeer will be responsible for learning about different file formats (CSV, XML, JSON, SHP) and the most efficient ways of parsing through and transforming data. This will ensure that modules are well designed and time efficient. She will ensure test cases include all relevant input file formats and malformed data inputs as well. She will learn about these best practices through the use of data parsing python tutorials online as well as researching libraries/prior implementations of open source GIS analysis tools. Through her co-op position, Abeer has significant experience working with various types of data and hence is the most suited member of our team for this task.   \\

\noindent Nicholas Lobo: \\
Nicholas has always been interested in learning about data analysis and normalization. Within the scope of this project, he has taken on the responsibility of learning about GPS data standards to help provide a wide range of inputs for all tests. He will ensure that the preprocessing unit can handle various types of GPS data as well as inform decisions about edge cases related to incorrect data. He can complete this task by consulting academic papers that detail the characteristics of and how to parse GPS data.\\


\end{document}
