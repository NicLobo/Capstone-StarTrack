{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h3 in c:\\python310\\lib\\site-packages (3.7.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install geopy\n",
    "!pip3 install numpy\n",
    "!pip3 install datetime\n",
    "!pip3 install h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Segment already exists\n",
      "Directory  ./Segment/trace3  already exists\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "hit\n",
      "    start_lat  start_long    end_lat  end_long                 start_time  \\\n",
      "0   51.339797   -0.257274  51.337471 -0.250760  2023-01-13 16:07:22+00:00   \n",
      "1   51.337471   -0.250760  51.337468 -0.250765  2023-01-13 16:14:53+00:00   \n",
      "2   51.337468   -0.250765  51.341486 -0.245979  2023-01-13 16:14:54+00:00   \n",
      "3   51.341486   -0.245979  51.341487 -0.245970  2023-01-13 16:29:33+00:00   \n",
      "4   51.341487   -0.245970  51.341515 -0.245849  2023-01-13 16:29:35+00:00   \n",
      "5   51.341515   -0.245849  51.341509 -0.245845  2023-01-13 16:29:39+00:00   \n",
      "6   51.341509   -0.245845  51.331587 -0.245060  2023-01-13 16:29:41+00:00   \n",
      "7   51.331587   -0.245060  51.331589 -0.245065  2023-01-13 16:48:44+00:00   \n",
      "8   51.331589   -0.245065  51.331583 -0.245052  2023-01-13 16:48:45+00:00   \n",
      "9   51.331583   -0.245052  51.331587 -0.245048  2023-01-13 16:48:46+00:00   \n",
      "10  51.331587   -0.245048  51.330478 -0.244132  2023-01-13 16:48:48+00:00   \n",
      "11  51.330478   -0.244132  51.330465 -0.244127  2023-01-13 16:49:37+00:00   \n",
      "12  51.330465   -0.244127  51.332750 -0.249083  2023-01-13 16:49:39+00:00   \n",
      "13  51.332750   -0.249083  51.332751 -0.249072  2023-01-13 16:53:28+00:00   \n",
      "14  51.332751   -0.249072  51.329084 -0.248652  2023-01-13 16:53:29+00:00   \n",
      "15  51.329084   -0.248652  51.329069 -0.248647  2023-01-13 16:56:12+00:00   \n",
      "16  51.329069   -0.248647  51.327344 -0.243845  2023-01-13 16:56:15+00:00   \n",
      "17  51.327344   -0.243845  51.327348 -0.243864  2023-01-13 16:59:04+00:00   \n",
      "18  51.327348   -0.243864  51.329834 -0.248292  2023-01-13 16:59:07+00:00   \n",
      "19  51.329834   -0.248292  51.329839 -0.248285  2023-01-13 17:01:23+00:00   \n",
      "20  51.329839   -0.248285  51.338914 -0.256617  2023-01-13 17:01:24+00:00   \n",
      "21  51.338914   -0.256617  51.338920 -0.256623  2023-01-13 17:10:22+00:00   \n",
      "22  51.338920   -0.256623  51.339931 -0.257127  2023-01-13 17:10:23+00:00   \n",
      "\n",
      "                     end_time  mode  \n",
      "0   2023-01-13 16:14:53+00:00     1  \n",
      "1   2023-01-13 16:14:54+00:00     0  \n",
      "2   2023-01-13 16:29:33+00:00     1  \n",
      "3   2023-01-13 16:29:35+00:00     0  \n",
      "4   2023-01-13 16:29:39+00:00     1  \n",
      "5   2023-01-13 16:29:41+00:00     0  \n",
      "6   2023-01-13 16:48:44+00:00     1  \n",
      "7   2023-01-13 16:48:45+00:00     0  \n",
      "8   2023-01-13 16:48:46+00:00     1  \n",
      "9   2023-01-13 16:48:48+00:00     0  \n",
      "10  2023-01-13 16:49:37+00:00     1  \n",
      "11  2023-01-13 16:49:39+00:00     0  \n",
      "12  2023-01-13 16:53:28+00:00     1  \n",
      "13  2023-01-13 16:53:29+00:00     0  \n",
      "14  2023-01-13 16:56:12+00:00     1  \n",
      "15  2023-01-13 16:56:15+00:00     0  \n",
      "16  2023-01-13 16:59:04+00:00     1  \n",
      "17  2023-01-13 16:59:07+00:00     0  \n",
      "18  2023-01-13 17:01:23+00:00     1  \n",
      "19  2023-01-13 17:01:24+00:00     0  \n",
      "20  2023-01-13 17:10:22+00:00     1  \n",
      "21  2023-01-13 17:10:23+00:00     0  \n",
      "22  2023-01-13 17:11:08+00:00     1  \n"
     ]
    }
   ],
   "source": [
    "# @file createEpisode.ipynb\n",
    "# @author Team GIS Gang\n",
    "# @brief This notebook aims to generate Trip Episodes based on the given datasets of points\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import datetime \n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import h3\n",
    "import geopy.distance\n",
    "import geopy as gp\n",
    "\n",
    "os.chdir(\"../src/\")\n",
    "\n",
    "#INPUT TRACE.CSV\n",
    "#OUTPUT POINTS.CSV\n",
    "\n",
    "# @param csv_path:\n",
    "# @param title:\n",
    "# @return an .csv file that consists of points\n",
    "def createSegments(csv_path, title):\n",
    "\n",
    "    #Reads csv and store in data frame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[[\"lat\",\"long\",\"time\"]]\n",
    "    df['time']= pd.to_datetime(df['time'])\n",
    "    df['index_column'] = df.index\n",
    "\n",
    "\n",
    "    #Calculate stepsize using start and end time of dataset\n",
    "    starttime = pd.to_datetime(df['time'].iloc[0])\n",
    "    endtime = pd.to_datetime(df['time'].iloc[-1])\n",
    "    totaltime = pd.Timedelta(endtime - starttime).seconds \n",
    "    stepsize = (round(len(df)/totaltime)) \n",
    "\n",
    "    #Trim points based on step size\n",
    "    if(stepsize != 0):\n",
    "        df = df.drop(df[df.index_column%stepsize !=0].index)\n",
    "        df = df.reset_index()\n",
    "    df = df[[\"lat\",\"long\",\"time\"]]\n",
    "\n",
    "\n",
    "    # Create Segment Directory\n",
    "    try: \n",
    "        os.mkdir(\"Segment\")\n",
    "        print(\"Directory Segment Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory Segment already exists\")\n",
    "\n",
    "    #Create trace directory in segment directory\n",
    "    try: \n",
    "        path = \"./Segment/\"+title\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory \" , path ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , path ,  \" already exists\")\n",
    "\n",
    "\n",
    "    #Saves trip points to csv file \n",
    "    df.to_csv(path+\"/points.csv\", index=False)\n",
    "\n",
    "\n",
    "#INPUT POINTS.CSV\n",
    "#OUTPUT VELOCITIES.CSV\n",
    "def createVelocities(csv_path):\n",
    "    \n",
    "    #Join the points cvs file by index n and n+1\n",
    "    df = pd.read_csv(csv_path+\"/points.csv\")\n",
    "    df2= df.iloc[:-1 , :]\n",
    "    df1 = df.tail(-1)\n",
    "    df1 = df1.reset_index()\n",
    "\n",
    "\n",
    "    velocities = pd.DataFrame(columns= [\"start_lat\",\"start_long\",\"end_lat\",\"end_long\",\"start_time\",\"end_time\",\"total_time\",\"total_distance\",\"velocity\"])\n",
    "    velocities[\"start_lat\"] = df1[\"lat\"]\n",
    "    velocities[\"start_long\"] = df1[\"long\"]\n",
    "    velocities[\"end_lat\"] = df2[\"lat\"]\n",
    "    velocities[\"end_long\"] = df2[\"long\"]\n",
    "    velocities[\"start_time\"] = pd.to_datetime(df1['time'])\n",
    "    velocities[\"end_time\"] =  pd.to_datetime(df2['time'])\n",
    "    velocities[\"total_time\"] = (velocities[\"end_time\"] - velocities[\"start_time\"]).dt.total_seconds().abs()\n",
    "    velocities['total_distance'] = velocities.apply(lambda x: gp.distance.distance((x[0], x[1]), (x[2], x[3])).m, axis=1)\n",
    "    velocities['velocity'] = velocities['total_distance'] / (velocities['total_time'])\n",
    "\n",
    "    #Saves trip segement to csv file\n",
    "    velocities.to_csv(csv_path+\"/velocities.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "class mode(Enum):\n",
    "    STOP = 0\n",
    "    WALK = 1\n",
    "    DRIVE = 10\n",
    "\n",
    "\n",
    "#INPUT VELOCITY.CSV\n",
    "#OUTPUT EPISODE.CSV\n",
    "def generateEpisodes(csv_path):\n",
    "\n",
    "    df = pd.read_csv(csv_path+\"/velocities.csv\") \n",
    "    episode= pd.DataFrame(columns= [\"start_lat\",\"start_long\",\"end_lat\",\"end_long\",\"start_time\",\"end_time\",\"mode\"])\n",
    "\n",
    "    startVel = df['velocity'].iloc[0] \n",
    "    startIndex = 0\n",
    "    currMode = mode.STOP\n",
    "    endIndex = 0\n",
    "\n",
    "    if( startVel >= mode.WALK.value and startVel < mode.DRIVE.value):\n",
    "        currMode = mode.WALK\n",
    "    \n",
    "    elif(startVel >= mode.DRIVE.value):\n",
    "        currMode = mode.DRIVE\n",
    "\n",
    "    for index in range(1,len(df)):\n",
    "\n",
    "        prevIndex = index - 1\n",
    "        endVel =  df['velocity'].iloc[index]\n",
    "        endMode = currMode\n",
    "        noChange = True\n",
    "        \n",
    "        starttime = pd.to_datetime(df['start_time'].iloc[startIndex])\n",
    "        endtime = pd.to_datetime(df['end_time'].iloc[index])\n",
    "        totaltime = pd.Timedelta(endtime - starttime).seconds \n",
    "\n",
    "        if( endVel >= mode.WALK.value and endVel < mode.DRIVE.value):\n",
    "            endMode = mode.WALK\n",
    "        elif(endVel >= mode.DRIVE.value):\n",
    "            endMode = mode.DRIVE\n",
    "        else: \n",
    "            endMode = mode.STOP\n",
    "\n",
    "        if(currMode != endMode):\n",
    "\n",
    "            new_row = [df['start_lat'].iloc[startIndex] ,\n",
    "                df['start_long'].iloc[startIndex] ,\n",
    "                df['end_lat'].iloc[index] ,\n",
    "                df['end_long'].iloc[index] ,\n",
    "                df['start_time'].iloc[startIndex],\n",
    "                df['end_time'].iloc[index],\n",
    "                currMode.value]    \n",
    "\n",
    "            episode.loc[len(episode)] = new_row\n",
    "            currMode = endMode\n",
    "            startIndex = prevIndex\n",
    "\n",
    "\n",
    "        if( index == len(df)-1 and noChange):\n",
    "            new_row = [df['start_lat'].iloc[startIndex] ,\n",
    "                df['start_long'].iloc[startIndex] ,\n",
    "                df['end_lat'].iloc[index] ,\n",
    "                df['end_long'].iloc[index] ,\n",
    "                df['start_time'].iloc[startIndex],\n",
    "                df['end_time'].iloc[index],\n",
    "                currMode.value]    \n",
    "\n",
    "            episode.loc[len(episode)] = new_row\n",
    "            currMode = endMode\n",
    "            startIndex = prevIndex\n",
    "\n",
    "\n",
    "    episode.to_csv(csv_path+\"/episode.csv\", index=False)\n",
    "\n",
    "\n",
    "def cleanEpisode(csv_path):\n",
    "    episode = pd.read_csv(csv_path+\"/episode.csv\") \n",
    "\n",
    "    for index in range(len(episode)):\n",
    "        starttime = pd.to_datetime(episode['start_time'].iloc[index]) \n",
    "        endtime = pd.to_datetime(episode['end_time'].iloc[index])\n",
    "        timePassed = pd.Timedelta(endtime - starttime).seconds \n",
    "\n",
    "        if(episode['mode'].iloc[index] == mode.STOP.value and timePassed < 60 and index <len(episode)-1):\n",
    "            print(episode.index[index])\n",
    "            episode['start_time'].iloc[index+1]\n",
    "            episode.drop([episode.index[index]])\n",
    "    print(episode)\n",
    "    episode.to_csv(csv_path+\"/episode.csv\", index=False)\n",
    "\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\n",
    "# createVelocities(\"./Segment/trace1\")\n",
    "# generateEpisodes(\"./Segment/trace1\")\n",
    "# cleanEpisode(\"./Segment/trace1\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_2.csv\",\"trace2\")\n",
    "# createVelocities(\"./Segment/trace2\")\n",
    "# generateEpisodes(\"./Segment/trace2\")\n",
    "# cleanEpisode(\"./Segment/trace2\")\n",
    "\n",
    "createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\") \n",
    "createVelocities(\"./Segment/trace3\")\n",
    "generateEpisodes(\"./Segment/trace3\")\n",
    "cleanEpisode(\"./Segment/trace3\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../SHPfiles/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 25\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# createVelocities(\"./Segment/trace1\")\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# generateEpisodes(\"./Segment/trace1\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# createVelocities(\"./Segment/trace3\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m targetPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHPfiles/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(targetPath)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#Loops through each csvfile, creates point SHP file and writes to the new directory\u001b[39;00m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../SHPfiles/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import datetime \n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import h3\n",
    "import geopy.distance\n",
    "import geopy as gp\n",
    "# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\n",
    "# createVelocities(\"./Segment/trace1\")\n",
    "# generateEpisodes(\"./Segment/trace1\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_2.csv\",\"trace2\")\n",
    "# createVelocities(\"./Segment/trace2\")\n",
    "# generateEpisodes(\"./Segment/trace2\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\")\n",
    "# createVelocities(\"./Segment/trace3\")\n",
    "\n",
    "\n",
    "targetPath = os.path.join(\"../\", \"SHPfiles/\")\n",
    "os.mkdir(targetPath)\n",
    "os.chdir(targetPath)\n",
    "#Loops through each csvfile, creates point SHP file and writes to the new directory\n",
    "csvfile = \"/Users/Nicholas/Desktop/Capstone-yoGERT/src/Segment/trace1/points.csv\"\n",
    "print(csvfile)\n",
    "data = pd.read_csv(csvfile)\n",
    "dataGDF = gpd.GeoDataFrame(data, geometry = gpd.points_from_xy(data['long'], data['lat']))\n",
    "#Standardized ESRI wkt projection\n",
    "ESRI_WKT = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]]'\n",
    "shpfilename = \"travelepisodew.shp\"\n",
    "dataGDF.to_file(filename=shpfilename, driver = 'ESRI Shapefile', crs=ESRI_WKT)\n",
    "\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "map_2 = KeplerGl()\n",
    "filename = \"data\"\n",
    "map_2.add_data(data=gpd.read_file(\"../SHPfiles/travelepisodew.shp\"), name=filename)\n",
    "map_2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ec6aae98d2e3fd85bca6a6a984ca4f59b9dba7dbd140565e5af6ee95c422cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
