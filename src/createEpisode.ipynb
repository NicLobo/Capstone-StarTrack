{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h3 in c:\\python310\\lib\\site-packages (3.7.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install geopy\n",
    "!pip3 install numpy\n",
    "!pip3 install datetime\n",
    "!pip3 install h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Segment already exists\n",
      "Directory  ./Segment/trace3  already exists\n",
      "[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicholas\\AppData\\Local\\Temp\\ipykernel_17384\\4137723205.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  episode['start_time'].iloc[index+1] =  starttime\n"
     ]
    }
   ],
   "source": [
    "# @file createEpisode.ipynb\n",
    "# @author Team GIS Gang\n",
    "# @brief This notebook aims to generate Trip Episodes based on the given datasets of points\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import datetime \n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import h3\n",
    "import geopy.distance\n",
    "import geopy as gp\n",
    "\n",
    "os.chdir(\"../src/\")\n",
    "\n",
    "#INPUT TRACE.CSV\n",
    "#OUTPUT POINTS.CSV\n",
    "\n",
    "# @param csv_path:\n",
    "# @param title:\n",
    "# @return an .csv file that consists of points\n",
    "def createSegments(csv_path, title):\n",
    "\n",
    "    #Reads csv and store in data frame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df = df[[\"lat\",\"long\",\"time\"]]\n",
    "    df['time']= pd.to_datetime(df['time'])\n",
    "    df['index_column'] = df.index\n",
    "\n",
    "\n",
    "    #Calculate stepsize using start and end time of dataset\n",
    "    starttime = pd.to_datetime(df['time'].iloc[0])\n",
    "    endtime = pd.to_datetime(df['time'].iloc[-1])\n",
    "    totaltime = pd.Timedelta(endtime - starttime).seconds \n",
    "    stepsize = (round(len(df)/totaltime)) \n",
    "\n",
    "    #Trim points based on step size\n",
    "    if(stepsize != 0):\n",
    "        df = df.drop(df[df.index_column%stepsize !=0].index)\n",
    "        df = df.reset_index()\n",
    "    df = df[[\"lat\",\"long\",\"time\"]]\n",
    "\n",
    "\n",
    "    # Create Segment Directory\n",
    "    try: \n",
    "        os.mkdir(\"Segment\")\n",
    "        print(\"Directory Segment Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory Segment already exists\")\n",
    "\n",
    "    #Create trace directory in segment directory\n",
    "    try: \n",
    "        path = \"./Segment/\"+title\n",
    "        os.mkdir(path)\n",
    "        print(\"Directory \" , path ,  \" Created \") \n",
    "    except FileExistsError:\n",
    "        print(\"Directory \" , path ,  \" already exists\")\n",
    "\n",
    "\n",
    "    #Saves trip points to csv file \n",
    "    df.to_csv(path+\"/points.csv\", index=False)\n",
    "\n",
    "\n",
    "#INPUT POINTS.CSV\n",
    "#OUTPUT VELOCITIES.CSV\n",
    "def createVelocities(csv_path):\n",
    "    \n",
    "    #Join the points cvs file by index n and n+1\n",
    "    df = pd.read_csv(csv_path+\"/points.csv\")\n",
    "    df2= df.iloc[:-1 , :]\n",
    "    df1 = df.tail(-1)\n",
    "    df1 = df1.reset_index()\n",
    "\n",
    "\n",
    "    velocities = pd.DataFrame(columns= [\"start_lat\",\"start_long\",\"end_lat\",\"end_long\",\"start_time\",\"end_time\",\"total_time\",\"total_distance\",\"velocity\"])\n",
    "    velocities[\"start_lat\"] = df1[\"lat\"]\n",
    "    velocities[\"start_long\"] = df1[\"long\"]\n",
    "    velocities[\"end_lat\"] = df2[\"lat\"]\n",
    "    velocities[\"end_long\"] = df2[\"long\"]\n",
    "    velocities[\"start_time\"] = pd.to_datetime(df1['time'])\n",
    "    velocities[\"end_time\"] =  pd.to_datetime(df2['time'])\n",
    "    velocities[\"total_time\"] = (velocities[\"end_time\"] - velocities[\"start_time\"]).dt.total_seconds().abs()\n",
    "    velocities['total_distance'] = velocities.apply(lambda x: gp.distance.distance((x[0], x[1]), (x[2], x[3])).m, axis=1)\n",
    "    velocities['velocity'] = velocities['total_distance'] / (velocities['total_time'])\n",
    "\n",
    "    #Saves trip segement to csv file\n",
    "    velocities.to_csv(csv_path+\"/velocities.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "from enum import Enum\n",
    "class mode(Enum):\n",
    "    STOP = 0\n",
    "    WALK = 1\n",
    "    DRIVE = 10\n",
    "\n",
    "\n",
    "#INPUT VELOCITY.CSV\n",
    "#OUTPUT EPISODE.CSV\n",
    "def generateEpisodes(csv_path):\n",
    "\n",
    "    df = pd.read_csv(csv_path+\"/velocities.csv\") \n",
    "    episode= pd.DataFrame(columns= [\"start_lat\",\"start_long\",\"end_lat\",\"end_long\",\"start_time\",\"end_time\",\"mode\"])\n",
    "\n",
    "    startVel = df['velocity'].iloc[0] \n",
    "    startIndex = 0\n",
    "    currMode = mode.STOP\n",
    "    endIndex = 0\n",
    "\n",
    "    if( startVel >= mode.WALK.value and startVel < mode.DRIVE.value):\n",
    "        currMode = mode.WALK\n",
    "    \n",
    "    elif(startVel >= mode.DRIVE.value):\n",
    "        currMode = mode.DRIVE\n",
    "\n",
    "    for index in range(1,len(df)):\n",
    "\n",
    "        prevIndex = index - 1\n",
    "        endVel =  df['velocity'].iloc[index]\n",
    "        endMode = currMode\n",
    "        noChange = True\n",
    "        \n",
    "        starttime = pd.to_datetime(df['start_time'].iloc[startIndex])\n",
    "        endtime = pd.to_datetime(df['end_time'].iloc[index])\n",
    "        totaltime = pd.Timedelta(endtime - starttime).seconds \n",
    "\n",
    "        if( endVel >= mode.WALK.value and endVel < mode.DRIVE.value):\n",
    "            endMode = mode.WALK\n",
    "        elif(endVel >= mode.DRIVE.value):\n",
    "            endMode = mode.DRIVE\n",
    "        else: \n",
    "            endMode = mode.STOP\n",
    "\n",
    "        if(currMode != endMode):\n",
    "\n",
    "            new_row = [df['start_lat'].iloc[startIndex] ,\n",
    "                df['start_long'].iloc[startIndex] ,\n",
    "                df['end_lat'].iloc[index] ,\n",
    "                df['end_long'].iloc[index] ,\n",
    "                df['start_time'].iloc[startIndex],\n",
    "                df['end_time'].iloc[index],\n",
    "                currMode]    \n",
    "\n",
    "            episode.loc[len(episode)] = new_row\n",
    "            currMode = endMode\n",
    "            startIndex = prevIndex\n",
    "\n",
    "\n",
    "        if( index == len(df)-1 and noChange):\n",
    "            new_row = [df['start_lat'].iloc[startIndex] ,\n",
    "                df['start_long'].iloc[startIndex] ,\n",
    "                df['end_lat'].iloc[index] ,\n",
    "                df['end_long'].iloc[index] ,\n",
    "                df['start_time'].iloc[startIndex],\n",
    "                df['end_time'].iloc[index],\n",
    "                currMode]    \n",
    "\n",
    "            episode.loc[len(episode)] = new_row\n",
    "            currMode = endMode\n",
    "            startIndex = prevIndex\n",
    "\n",
    "\n",
    "    episode.to_csv(csv_path+\"/episode.csv\", index=False)\n",
    "\n",
    "\n",
    "def cleanEpisode(csv_path):\n",
    "    episode = pd.read_csv(csv_path+\"/episode.csv\") \n",
    "\n",
    "    droplist = []\n",
    "    timelist = []\n",
    "    indexlist = []\n",
    "\n",
    "    for index in range(len(episode)):\n",
    "        starttime = pd.to_datetime(episode['start_time'].iloc[index]) \n",
    "        endtime = pd.to_datetime(episode['end_time'].iloc[index])\n",
    "        timePassed = pd.Timedelta(endtime - starttime).seconds \n",
    "\n",
    "        if(episode['mode'].iloc[index] == 'mode.STOP' and timePassed < 60 and index <len(episode)-1):\n",
    "            droplist.append(index)\n",
    "            episode['start_time'].iloc[index+1] =  starttime\n",
    "\n",
    "\n",
    "\n",
    "    episode = episode.drop(droplist)\n",
    "    episode = episode.reset_index(drop=True)\n",
    "    episode.to_csv(csv_path+\"/episode.csv\", index=False)\n",
    "\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\n",
    "# createVelocities(\"./Segment/trace1\")\n",
    "# generateEpisodes(\"./Segment/trace1\")\n",
    "# cleanEpisode(\"./Segment/trace1\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_2.csv\",\"trace2\")\n",
    "# createVelocities(\"./Segment/trace2\")\n",
    "# generateEpisodes(\"./Segment/trace2\")\n",
    "# cleanEpisode(\"./Segment/trace2\")\n",
    "\n",
    "createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\") \n",
    "createVelocities(\"./Segment/trace3\")\n",
    "generateEpisodes(\"./Segment/trace3\")\n",
    "cleanEpisode(\"./Segment/trace3\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: '../SHPfiles/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 25\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# createVelocities(\"./Segment/trace1\")\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# generateEpisodes(\"./Segment/trace1\")\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\")\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# createVelocities(\"./Segment/trace3\")\u001b[39;00m\n\u001b[0;32m     24\u001b[0m targetPath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSHPfiles/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetPath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(targetPath)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#Loops through each csvfile, creates point SHP file and writes to the new directory\u001b[39;00m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: '../SHPfiles/'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import datetime \n",
    "from os.path import join\n",
    "import numpy as np\n",
    "import h3\n",
    "import geopy.distance\n",
    "import geopy as gp\n",
    "# createSegments(\"../src/exampleDataset/trace_1.csv\",\"trace1\")\n",
    "# createVelocities(\"./Segment/trace1\")\n",
    "# generateEpisodes(\"./Segment/trace1\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_2.csv\",\"trace2\")\n",
    "# createVelocities(\"./Segment/trace2\")\n",
    "# generateEpisodes(\"./Segment/trace2\")\n",
    "\n",
    "# createSegments(\"../src/exampleDataset/trace_3.csv\",\"trace3\")\n",
    "# createVelocities(\"./Segment/trace3\")\n",
    "\n",
    "\n",
    "targetPath = os.path.join(\"../\", \"SHPfiles/\")\n",
    "os.mkdir(targetPath)\n",
    "os.chdir(targetPath)\n",
    "#Loops through each csvfile, creates point SHP file and writes to the new directory\n",
    "csvfile = \"/Users/Nicholas/Desktop/Capstone-yoGERT/src/Segment/trace1/points.csv\"\n",
    "print(csvfile)\n",
    "data = pd.read_csv(csvfile)\n",
    "dataGDF = gpd.GeoDataFrame(data, geometry = gpd.points_from_xy(data['long'], data['lat']))\n",
    "#Standardized ESRI wkt projection\n",
    "ESRI_WKT = 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137,298.257223563]],PRIMEM[\"Greenwich\",0],UNIT[\"Degree\",0.017453292519943295]]'\n",
    "shpfilename = \"travelepisodew.shp\"\n",
    "dataGDF.to_file(filename=shpfilename, driver = 'ESRI Shapefile', crs=ESRI_WKT)\n",
    "\n",
    "\n",
    "from keplergl import KeplerGl\n",
    "map_2 = KeplerGl()\n",
    "filename = \"data\"\n",
    "map_2.add_data(data=gpd.read_file(\"../SHPfiles/travelepisodew.shp\"), name=filename)\n",
    "map_2\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
